#!/usr/bin/env python3
"""
Coqui TTS è®­ç»ƒæ¥å£å°è£…æ¨¡å—

å°è£… Coqui TTS è®­ç»ƒ APIï¼Œæä¾›è®­ç»ƒå‚æ•°é…ç½®ã€æ¨¡å‹è¾“å‡ºç®¡ç†å’Œè®­ç»ƒè¿›åº¦å›è°ƒåŠŸèƒ½ã€‚
"""

import os
import json
import shutil
import time
import logging
from pathlib import Path
from dataclasses import dataclass, field
from typing import Callable, Optional, List, Dict, Any
from enum import Enum

from modules.training.train_config import TrainConfig, AudioConfig


logger = logging.getLogger(__name__)


class TrainingStatus(Enum):
    """è®­ç»ƒçŠ¶æ€æšä¸¾"""
    IDLE = "idle"               # ç©ºé—²çŠ¶æ€
    PREPARING = "preparing"     # å‡†å¤‡ä¸­
    TRAINING = "training"       # è®­ç»ƒä¸­
    PAUSED = "paused"          # å·²æš‚åœ
    COMPLETED = "completed"     # å·²å®Œæˆ
    FAILED = "failed"          # å¤±è´¥
    CANCELLED = "cancelled"     # å·²å–æ¶ˆ


@dataclass
class TrainingProgress:
    """è®­ç»ƒè¿›åº¦ä¿¡æ¯"""
    current_epoch: int = 0          # å½“å‰ epoch
    total_epochs: int = 0           # æ€» epoch æ•°
    current_step: int = 0           # å½“å‰æ­¥æ•°
    total_steps: int = 0            # æ€»æ­¥æ•°
    loss: float = 0.0               # å½“å‰æŸå¤±å€¼
    learning_rate: float = 0.0      # å½“å‰å­¦ä¹ ç‡
    elapsed_time: float = 0.0       # å·²ç”¨æ—¶é—´ï¼ˆç§’ï¼‰
    estimated_remaining: float = 0.0 # é¢„ä¼°å‰©ä½™æ—¶é—´ï¼ˆç§’ï¼‰
    status: TrainingStatus = TrainingStatus.IDLE
    message: str = ""               # çŠ¶æ€æ¶ˆæ¯
    
    # Coqui TTS ç‰¹æœ‰çš„è¿›åº¦ä¿¡æ¯
    avg_loss: float = 0.0           # å¹³å‡æŸå¤±å€¼
    mel_loss: float = 0.0           # Mel æŸå¤±
    duration_loss: float = 0.0      # æ—¶é•¿æŸå¤±
    kl_loss: float = 0.0            # KL æ•£åº¦æŸå¤±ï¼ˆVITSï¼‰
    
    @property
    def progress_percentage(self) -> float:
        """è®¡ç®—è®­ç»ƒè¿›åº¦ç™¾åˆ†æ¯”"""
        if self.total_epochs == 0:
            return 0.0
        return (self.current_epoch / self.total_epochs) * 100
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "current_epoch": self.current_epoch,
            "total_epochs": self.total_epochs,
            "current_step": self.current_step,
            "total_steps": self.total_steps,
            "loss": self.loss,
            "avg_loss": self.avg_loss,
            "mel_loss": self.mel_loss,
            "duration_loss": self.duration_loss,
            "kl_loss": self.kl_loss,
            "learning_rate": self.learning_rate,
            "elapsed_time": self.elapsed_time,
            "estimated_remaining": self.estimated_remaining,
            "progress_percentage": self.progress_percentage,
            "status": self.status.value,
            "message": self.message
        }


@dataclass
class TrainingResult:
    """è®­ç»ƒç»“æœä¿¡æ¯"""
    success: bool = False           # æ˜¯å¦æˆåŠŸ
    model_path: Optional[Path] = None  # æ¨¡å‹æ–‡ä»¶è·¯å¾„
    total_epochs: int = 0           # è®­ç»ƒçš„æ€» epoch æ•°
    final_loss: float = 0.0         # æœ€ç»ˆæŸå¤±å€¼
    training_time: float = 0.0      # æ€»è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰
    model_size: int = 0             # æ¨¡å‹æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    error_message: str = ""         # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    checkpoint_path: Optional[Path] = None  # æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
    config_path: Optional[Path] = None  # æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
    logs: List[str] = field(default_factory=list)  # è®­ç»ƒæ—¥å¿—
    
    # ONNX å¯¼å‡ºç›¸å…³
    onnx_model_path: Optional[Path] = None  # ONNX æ¨¡å‹è·¯å¾„
    onnx_config_path: Optional[Path] = None  # ONNX é…ç½®è·¯å¾„
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "success": self.success,
            "model_path": str(self.model_path) if self.model_path else None,
            "total_epochs": self.total_epochs,
            "final_loss": self.final_loss,
            "training_time": self.training_time,
            "model_size": self.model_size,
            "error_message": self.error_message,
            "checkpoint_path": str(self.checkpoint_path) if self.checkpoint_path else None,
            "config_path": str(self.config_path) if self.config_path else None,
            "onnx_model_path": str(self.onnx_model_path) if self.onnx_model_path else None,
            "onnx_config_path": str(self.onnx_config_path) if self.onnx_config_path else None
        }


# è¿›åº¦å›è°ƒå‡½æ•°ç±»å‹
ProgressCallback = Callable[[TrainingProgress], None]


class CoquiTrainer:
    """
    Coqui TTS è®­ç»ƒå™¨
    
    å°è£… Coqui TTS æ¨¡å‹è®­ç»ƒåŠŸèƒ½ï¼Œæ”¯æŒï¼š
    - å¤šç§æ¨¡å‹æ¶æ„ï¼ˆVITSã€FastSpeech2ã€Tacotron2ã€Glow-TTSï¼‰
    - è®­ç»ƒå‚æ•°é…ç½®
    - è®­ç»ƒè¿›åº¦ç›‘æ§
    - æ–­ç‚¹ç»­è®­
    - æ¨¡å‹è¾“å‡ºç®¡ç†
    - ONNX å¯¼å‡º
    """
    
    def __init__(self, config: TrainConfig, verbose: bool = False):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            config: è®­ç»ƒé…ç½®
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        self.config = config
        self.verbose = verbose
        self._progress = TrainingProgress()
        self._callbacks: List[ProgressCallback] = []
        self._start_time: float = 0
        self._should_stop: bool = False
        self._logs: List[str] = []
        self._trainer = None  # Coqui TTS Trainer å®ä¾‹
        
    def add_progress_callback(self, callback: ProgressCallback) -> None:
        """
        æ·»åŠ è¿›åº¦å›è°ƒå‡½æ•°
        
        Args:
            callback: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶ TrainingProgress å‚æ•°
        """
        self._callbacks.append(callback)
    
    def remove_progress_callback(self, callback: ProgressCallback) -> None:
        """
        ç§»é™¤è¿›åº¦å›è°ƒå‡½æ•°
        
        Args:
            callback: è¦ç§»é™¤çš„å›è°ƒå‡½æ•°
        """
        if callback in self._callbacks:
            self._callbacks.remove(callback)
    
    def _notify_progress(self) -> None:
        """é€šçŸ¥æ‰€æœ‰å›è°ƒå‡½æ•°å½“å‰è¿›åº¦"""
        for callback in self._callbacks:
            try:
                callback(self._progress)
            except Exception as e:
                self._log(f"è¿›åº¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
    
    def _log(self, message: str) -> None:
        """
        è®°å½•æ—¥å¿—
        
        Args:
            message: æ—¥å¿—æ¶ˆæ¯
        """
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self._logs.append(log_entry)
        if self.verbose:
            print(log_entry)
        logger.info(message)
    
    def _update_progress(self, **kwargs) -> None:
        """
        æ›´æ–°è®­ç»ƒè¿›åº¦
        
        Args:
            **kwargs: è¦æ›´æ–°çš„è¿›åº¦å±æ€§
        """
        for key, value in kwargs.items():
            if hasattr(self._progress, key):
                setattr(self._progress, key, value)
        
        # è®¡ç®—å·²ç”¨æ—¶é—´
        if self._start_time > 0:
            self._progress.elapsed_time = time.time() - self._start_time
            
            # ä¼°ç®—å‰©ä½™æ—¶é—´
            if self._progress.current_step > 0 and self._progress.total_steps > 0:
                avg_time_per_step = self._progress.elapsed_time / self._progress.current_step
                remaining_steps = self._progress.total_steps - self._progress.current_step
                self._progress.estimated_remaining = avg_time_per_step * remaining_steps
        
        self._notify_progress()
    
    def _apply_bfloat16_fix(self) -> None:
        """
        åº”ç”¨ BFloat16 å…¼å®¹æ€§ä¿®å¤
        
        åœ¨ Apple Silicon ä¸Šä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒæ—¶ï¼ŒPyTorch ä¼šä½¿ç”¨ BFloat16 æ ¼å¼ï¼Œ
        ä½† numpy ä¸æ”¯æŒ BFloat16ï¼Œå¯¼è‡´åœ¨ç”Ÿæˆè®­ç»ƒæ—¥å¿—å›¾è¡¨æ—¶å‡ºé”™ã€‚
        è¿™ä¸ªæ–¹æ³•é€šè¿‡ monkey patch ä¿®å¤ TTS åº“ä¸­çš„ç›¸å…³ä»£ç ã€‚
        
        ä»…åœ¨ä»¥ä¸‹æ¡ä»¶ä¸‹åº”ç”¨ä¿®å¤ï¼š
        1. æ“ä½œç³»ç»Ÿä¸º macOS (Darwin)
        2. CPU æ¶æ„ä¸º ARM64 (Apple Silicon)
        3. PyTorch æ”¯æŒ BFloat16
        """
        try:
            import platform
            import torch
            
            # æ£€æµ‹å¹³å°ï¼šåªåœ¨ macOS Apple Silicon ä¸Šåº”ç”¨ä¿®å¤
            system = platform.system()
            machine = platform.machine()
            
            # æ£€æŸ¥æ˜¯å¦ä¸º macOS
            if system != 'Darwin':
                self._log(f"â„¹ï¸  å½“å‰å¹³å° ({system}) ä¸éœ€è¦ BFloat16 ä¿®å¤ï¼Œè·³è¿‡")
                return
            
            # æ£€æŸ¥æ˜¯å¦ä¸º Apple Silicon (ARM64)
            if machine.lower() not in ['arm64', 'aarch64']:
                self._log(f"â„¹ï¸  å½“å‰æ¶æ„ ({machine}) ä¸éœ€è¦ BFloat16 ä¿®å¤ï¼Œè·³è¿‡")
                return
            
            # æ£€æŸ¥ PyTorch æ˜¯å¦æ”¯æŒ BFloat16
            # åœ¨ Apple Silicon ä¸Šï¼ŒBFloat16 æ”¯æŒé€šè¿‡ MPS åç«¯
            has_bfloat16_support = False
            try:
                # æ£€æŸ¥ MPS æ˜¯å¦å¯ç”¨ï¼ˆApple Silicon ç‰¹æœ‰ï¼‰
                if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    has_bfloat16_support = True
                # æˆ–è€…æ£€æŸ¥ CPU æ˜¯å¦æ”¯æŒ BFloat16
                elif hasattr(torch, 'bfloat16'):
                    # å°è¯•åˆ›å»ºä¸€ä¸ª BFloat16 å¼ é‡æ¥éªŒè¯æ”¯æŒ
                    test_tensor = torch.tensor([1.0], dtype=torch.bfloat16)
                    has_bfloat16_support = True
            except Exception:
                pass
            
            if not has_bfloat16_support:
                self._log("â„¹ï¸  å½“å‰ PyTorch ä¸æ”¯æŒ BFloat16ï¼Œæ— éœ€åº”ç”¨ä¿®å¤")
                return
            
            # æ‰€æœ‰æ¡ä»¶æ»¡è¶³ï¼Œåº”ç”¨ä¿®å¤
            self._log(f"ğŸ”§ æ£€æµ‹åˆ° Apple Silicon ({machine})ï¼Œå‡†å¤‡åº”ç”¨ BFloat16 ä¿®å¤...")
            
            from TTS.vocoder.utils import generic_utils
            
            # ä¿å­˜åŸå§‹çš„ plot_results å‡½æ•°
            original_plot_results = generic_utils.plot_results
            
            def patched_plot_results(y_hat, y, ap, name_prefix):
                """ä¿®å¤åçš„ plot_results å‡½æ•°ï¼Œæ”¯æŒ BFloat16"""
                # å°† BFloat16 å¼ é‡è½¬æ¢ä¸º float32
                if isinstance(y_hat, (list, tuple)) and len(y_hat) > 0:
                    if hasattr(y_hat[0], 'dtype') and y_hat[0].dtype == torch.bfloat16:
                        y_hat = [item.float() if hasattr(item, 'float') else item for item in y_hat]
                elif hasattr(y_hat, 'dtype') and y_hat.dtype == torch.bfloat16:
                    y_hat = y_hat.float()
                
                if isinstance(y, (list, tuple)) and len(y) > 0:
                    if hasattr(y[0], 'dtype') and y[0].dtype == torch.bfloat16:
                        y = [item.float() if hasattr(item, 'float') else item for item in y]
                elif hasattr(y, 'dtype') and y.dtype == torch.bfloat16:
                    y = y.float()
                
                # è°ƒç”¨åŸå§‹å‡½æ•°
                return original_plot_results(y_hat, y, ap, name_prefix)
            
            # åº”ç”¨ monkey patch åˆ° generic_utils æ¨¡å—
            generic_utils.plot_results = patched_plot_results
            
            # åŒæ—¶ patch å·²ç»å¯¼å…¥ plot_results çš„æ¨¡å—
            # å› ä¸º vits.py åœ¨å¯¼å…¥æ—¶å·²ç»æ‰§è¡Œäº† from TTS.vocoder.utils.generic_utils import plot_results
            # æ‰€ä»¥éœ€è¦ç›´æ¥ä¿®æ”¹ vits æ¨¡å—ä¸­çš„å¼•ç”¨
            try:
                from TTS.tts.models import vits
                if hasattr(vits, 'plot_results'):
                    vits.plot_results = patched_plot_results
                
                # æ›´é‡è¦çš„æ˜¯ï¼špatch VITS æ¨¡å‹çš„ _log æ–¹æ³•
                # å› ä¸º _log æ–¹æ³•ä¸­æœ‰å¤šå¤„ç›´æ¥è°ƒç”¨ .numpy()ï¼Œéƒ½éœ€è¦å¤„ç† BFloat16
                if hasattr(vits, 'Vits'):
                    original_vits_log = vits.Vits._log
                    
                    def patched_vits_log(self, ap, batch, outputs, name_prefix="train"):
                        """ä¿®å¤åçš„ VITS._log æ–¹æ³•ï¼Œè‡ªåŠ¨å¤„ç† BFloat16"""
                        # å°†æ‰€æœ‰ BFloat16 å¼ é‡è½¬æ¢ä¸º float32
                        def convert_bfloat16(data):
                            """é€’å½’è½¬æ¢ BFloat16 å¼ é‡"""
                            if isinstance(data, dict):
                                return {k: convert_bfloat16(v) for k, v in data.items()}
                            elif isinstance(data, (list, tuple)):
                                return type(data)(convert_bfloat16(item) for item in data)
                            elif hasattr(data, 'dtype') and data.dtype == torch.bfloat16:
                                return data.float()
                            return data
                        
                        # è½¬æ¢ outputs ä¸­çš„æ‰€æœ‰ BFloat16 å¼ é‡
                        outputs = convert_bfloat16(outputs)
                        
                        # è°ƒç”¨åŸå§‹æ–¹æ³•
                        return original_vits_log(self, ap, batch, outputs, name_prefix)
                    
                    vits.Vits._log = patched_vits_log
                    self._log("âœ… å·²åº”ç”¨ BFloat16 å…¼å®¹æ€§ä¿®å¤ï¼ˆåŒ…æ‹¬ VITS._log æ–¹æ³•ï¼‰")
                else:
                    self._log("âœ… å·²åº”ç”¨ BFloat16 å…¼å®¹æ€§ä¿®å¤")
            except (ImportError, AttributeError) as e:
                self._log(f"âœ… å·²åº”ç”¨ BFloat16 å…¼å®¹æ€§ä¿®å¤ï¼ˆéƒ¨åˆ†åŠŸèƒ½: {e}ï¼‰")
            
        except ImportError:
            # å¦‚æœ TTS åº“æœªå®‰è£…ï¼Œå¿½ç•¥
            pass
        except Exception as e:
            self._log(f"âš ï¸  åº”ç”¨ BFloat16 ä¿®å¤æ—¶å‡ºé”™ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
    
    def _apply_mps_fix(self) -> None:
        """
        åº”ç”¨ MPS è®¾å¤‡æ”¯æŒä¿®å¤
        
        Trainer çš„ setup_torch_training_env å‡½æ•°ä¸æ”¯æŒ MPS è®¾å¤‡ï¼Œ
        ä¼šåœ¨ macOS ä¸Šå°è¯•è°ƒç”¨ torch.cuda.set_device() å¯¼è‡´é”™è¯¯ã€‚
        è¿™ä¸ªæ–¹æ³•é€šè¿‡ monkey patch ä¿®å¤ Trainer çš„è®¾å¤‡æ£€æµ‹é€»è¾‘ã€‚
        
        ä»…åœ¨ä»¥ä¸‹æ¡ä»¶ä¸‹åº”ç”¨ä¿®å¤ï¼š
        1. æ“ä½œç³»ç»Ÿä¸º macOS (Darwin)
        2. PyTorch æ”¯æŒ MPS
        3. MPS å¯ç”¨
        """
        try:
            import platform
            import torch
            
            # æ£€æµ‹å¹³å°ï¼šåªåœ¨ macOS ä¸Šåº”ç”¨ä¿®å¤
            system = platform.system()
            if system != 'Darwin':
                return
            
            # æ£€æŸ¥ MPS æ˜¯å¦å¯ç”¨
            if not (hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()):
                return
            
            self._log("ğŸ”§ æ£€æµ‹åˆ° MPS è®¾å¤‡ï¼Œå‡†å¤‡åº”ç”¨ MPS æ”¯æŒä¿®å¤...")
            
            # Patch setup_torch_training_env å‡½æ•°
            from trainer import trainer_utils
            import random
            import numpy as np
            import os
            
            # ä¿å­˜åŸå§‹å‡½æ•°
            original_setup = trainer_utils.setup_torch_training_env
            
            def patched_setup_torch_training_env(
                args,
                cudnn_enable,
                cudnn_benchmark,
                cudnn_deterministic,
                use_ddp=False,
                training_seed=54321,
                allow_tf32=False,
                gpu=None,
            ):
                """ä¿®å¤åçš„ setup_torch_training_envï¼Œæ”¯æŒ MPS è®¾å¤‡"""
                
                # æ£€æŸ¥æ˜¯å¦ä¸º MPS ç¯å¢ƒ
                is_mps = hasattr(torch.backends, 'mps') and torch.backends.mps.is_available()
                is_cuda = torch.cuda.is_available()
                
                if is_mps and not is_cuda:
                    # MPS ç¯å¢ƒï¼šä¸è°ƒç”¨ CUDA ç›¸å…³å‡½æ•°
                    
                    # è®¾ç½®éšæœºç§å­
                    random.seed(training_seed)
                    os.environ["PYTHONHASHSEED"] = str(training_seed)
                    np.random.seed(training_seed)
                    torch.manual_seed(training_seed)
                    
                    # MPS ä¸æ”¯æŒ CUDNNï¼Œè·³è¿‡ CUDNN è®¾ç½®
                    
                    # è¿”å› use_cuda=Falseï¼ˆè®© PyTorch è‡ªåŠ¨ä½¿ç”¨ MPSï¼‰
                    # num_gpus=1 è¡¨ç¤ºæœ‰ä¸€ä¸ªåŠ é€Ÿè®¾å¤‡ï¼ˆMPSï¼‰
                    return False, 1
                else:
                    # CUDA ç¯å¢ƒæˆ– CPUï¼šä½¿ç”¨åŸå§‹å‡½æ•°
                    return original_setup(
                        args,
                        cudnn_enable,
                        cudnn_benchmark,
                        cudnn_deterministic,
                        use_ddp,
                        training_seed,
                        allow_tf32,
                        gpu,
                    )
            
            # åº”ç”¨ monkey patch åˆ° trainer_utils æ¨¡å—
            trainer_utils.setup_torch_training_env = patched_setup_torch_training_env
            
            # å…³é”®ï¼šè¿˜éœ€è¦ patch trainer.trainer æ¨¡å—ä¸­çš„å¼•ç”¨
            # å› ä¸º Trainer ç±»ä½¿ç”¨äº† from trainer_utils import setup_torch_training_env
            # è¿™ä¼šåˆ›å»ºä¸€ä¸ªæœ¬åœ°å¼•ç”¨ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ Trainer å¯¼å…¥ä¹‹å‰å°±æ›¿æ¢å®ƒ
            import sys
            if 'trainer.trainer' in sys.modules:
                # å¦‚æœ trainer.trainer å·²ç»å¯¼å…¥ï¼Œéœ€è¦æ›¿æ¢å…¶ä¸­çš„å¼•ç”¨
                import trainer.trainer as trainer_module
                trainer_module.setup_torch_training_env = patched_setup_torch_training_env
            
            self._log("âœ… å·²åº”ç”¨ MPS è®¾å¤‡æ”¯æŒä¿®å¤")
            
        except ImportError:
            # å¦‚æœ trainer åº“æœªå®‰è£…ï¼Œå¿½ç•¥
            pass
        except Exception as e:
            self._log(f"âš ï¸  åº”ç”¨ MPS ä¿®å¤æ—¶å‡ºé”™ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")
    
    def _prepare_training_directory(self) -> Path:
        """
        å‡†å¤‡è®­ç»ƒç›®å½•ç»“æ„
        
        Returns:
            è®­ç»ƒå·¥ä½œç›®å½•è·¯å¾„
        """
        self._log("å‡†å¤‡è®­ç»ƒç›®å½•...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = self.config.output_path
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºè®­ç»ƒå·¥ä½œç›®å½•
        work_dir = output_dir / "training_workspace"
        work_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ£€æŸ¥ç‚¹ç›®å½•
        checkpoint_dir = work_dir / "checkpoints"
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = work_dir / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        model_dir = output_dir / "model"
        model_dir.mkdir(parents=True, exist_ok=True)
        
        self._log(f"è®­ç»ƒå·¥ä½œç›®å½•: {work_dir}")
        return work_dir
    
    def _create_coqui_config(self, dataset_path: Path) -> Any:
        """
        åˆ›å»º Coqui TTS è®­ç»ƒé…ç½®
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
            
        Returns:
            Coqui TTS é…ç½®å¯¹è±¡
        """
        self._log(f"åˆ›å»º {self.config.model_type.upper()} æ¨¡å‹é…ç½®...")
        
        try:
            from TTS.tts.configs.vits_config import VitsConfig
            from TTS.tts.configs.glow_tts_config import GlowTTSConfig
            from TTS.tts.configs.fastspeech2_config import Fastspeech2Config
            from TTS.tts.configs.tacotron2_config import Tacotron2Config
            from TTS.config import BaseAudioConfig, BaseDatasetConfig
            from TTS.tts.models.vits import Vits
        except ImportError as e:
            self._log(f"å¯¼å…¥ Coqui TTS é…ç½®å¤±è´¥: {e}")
            raise ImportError("Coqui TTS æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install TTS>=0.22.0")
        
        # åˆ›å»ºéŸ³é¢‘é…ç½®
        audio_config = BaseAudioConfig(
            sample_rate=self.config.sample_rate,
            hop_length=self.config.audio_config.hop_length,
            win_length=self.config.audio_config.win_length,
            fft_size=self.config.audio_config.fft_size,
            num_mels=self.config.audio_config.num_mels,
            mel_fmin=self.config.audio_config.mel_fmin,
            mel_fmax=self.config.audio_config.mel_fmax,
        )
        
        # åˆ›å»ºæ•°æ®é›†é…ç½®
        dataset_config = BaseDatasetConfig(
            formatter="ljspeech",
            meta_file_train="metadata.csv",
            path=str(dataset_path),
            language=self.config.language,
        )
        
        # æ£€æŸ¥æ•°æ®é›†å¤§å°ï¼ŒåŠ¨æ€è°ƒæ•´éªŒè¯é›†å‚æ•°
        metadata_file = dataset_path / "metadata.csv"
        num_samples = 0
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                num_samples = sum(1 for _ in f)
        
        # æ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´éªŒè¯é›†åˆ’åˆ†
        # å¯¹äºå°æ•°æ®é›†ï¼Œä½¿ç”¨æ›´å¤§çš„æ¯”ä¾‹æˆ–ç¦ç”¨éªŒè¯
        if num_samples < 10:
            # å°äº 10 ä¸ªæ ·æœ¬ï¼Œç¦ç”¨éªŒè¯é›†
            eval_split_size = 0.0
            run_eval = False
            self._log(f"æ•°æ®é›†è¿‡å° ({num_samples} ä¸ªæ ·æœ¬)ï¼Œç¦ç”¨éªŒè¯é›†")
        elif num_samples < 50:
            # å°äº 50 ä¸ªæ ·æœ¬ï¼Œä½¿ç”¨è¾ƒå¤§çš„éªŒè¯æ¯”ä¾‹
            eval_split_size = 0.2
            run_eval = True
            self._log(f"å°æ•°æ®é›† ({num_samples} ä¸ªæ ·æœ¬)ï¼ŒéªŒè¯é›†æ¯”ä¾‹è®¾ä¸º 20%")
        else:
            # æ­£å¸¸æ•°æ®é›†
            eval_split_size = 0.01
            run_eval = True
        
        # è·å–æœ‰æ•ˆè®¾å¤‡
        device = self.config.get_effective_device()
        
        # è®°å½•è®¾å¤‡ä¿¡æ¯ï¼ˆè®¾å¤‡ç®¡ç†ç”± Trainer è´Ÿè´£ï¼Œä¸åœ¨ Config ä¸­è®¾ç½®ï¼‰
        if device in ["cuda", "mps"]:
            self._log(f"âœ… å¯ç”¨ GPU åŠ é€Ÿ: {device.upper()}")
        else:
            self._log(f"âš ï¸  ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        
        # é€šç”¨è®­ç»ƒå‚æ•°
        # æ³¨æ„ï¼šæ–°ç‰ˆæœ¬çš„ Coqui TTS ä¸å†åœ¨ Config ä¸­è®¾ç½® use_cuda
        # è®¾å¤‡ç®¡ç†ç”± Trainer è´Ÿè´£ï¼Œä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å¯ç”¨çš„è®¾å¤‡
        common_args = {
            "audio": audio_config,
            "batch_size": self.config.batch_size,
            "eval_batch_size": max(1, self.config.batch_size // 2),
            "num_loader_workers": self.config.num_workers,
            "num_eval_loader_workers": 2,
            "run_eval": run_eval,
            "eval_split_size": eval_split_size,
            "test_delay_epochs": 5,
            "epochs": self.config.epochs,
            "lr": self.config.learning_rate,
            "print_step": self.config.print_interval,
            "save_step": self.config.checkpoint_interval,
            "save_n_checkpoints": 3,
            "save_best_after": 1000,
            "datasets": [dataset_config],
            "text_cleaner": self.config.text_cleaner,
            "use_phonemes": self.config.use_phonemes,
            "phoneme_language": self.config.phoneme_language if self.config.use_phonemes else None,
            "mixed_precision": self.config.mixed_precision,
        }
        
        # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºé…ç½®
        model_type = self.config.model_type.lower()
        
        if model_type == "vits":
            config = VitsConfig(**common_args)
            # è®¾ç½®æ¨¡å‹å‚æ•°ï¼ˆé€šè¿‡ model_args å¯¹è±¡ï¼‰
            config.model_args.num_chars = 256  # å°†æ ¹æ®å®é™…æ–‡æœ¬è°ƒæ•´
            config.model_args.out_channels = 513
            config.model_args.spec_segment_size = 32
            config.model_args.hidden_channels = 192
            config.model_args.hidden_channels_ffn_text_encoder = 768
            config.model_args.num_heads_text_encoder = 2
            config.model_args.num_layers_text_encoder = 6
            config.model_args.kernel_size_text_encoder = 3
            config.model_args.dropout_p_text_encoder = 0.1
            config.model_args.dropout_p_duration_predictor = 0.5
            # hidden_channels_dp, kernel_size_dp, num_layers_dp åœ¨æ–°ç‰ˆæœ¬ä¸­å·²ä¸å­˜åœ¨
            config.model_args.resblock_type_decoder = "1"
            config.model_args.resblock_kernel_sizes_decoder = [3, 7, 11]
            config.model_args.resblock_dilation_sizes_decoder = [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
            config.model_args.upsample_rates_decoder = [8, 8, 2, 2]
            config.model_args.upsample_initial_channel_decoder = 512
            config.model_args.upsample_kernel_sizes_decoder = [16, 16, 4, 4]
            config.model_args.use_sdp = True
        elif model_type == "glow_tts":
            config = GlowTTSConfig(
                **common_args,
            )
        elif model_type == "fast_speech2":
            config = Fastspeech2Config(
                **common_args,
            )
        elif model_type == "tacotron2":
            config = Tacotron2Config(
                **common_args,
            )
        else:
            self._log(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹ {model_type}ï¼Œä½¿ç”¨é»˜è®¤ VITS")
            config = VitsConfig(**common_args)
        
        return config
    
    def _create_training_callback(self):
        """
        åˆ›å»º Coqui TTS è®­ç»ƒå›è°ƒ
        
        Returns:
            è®­ç»ƒå›è°ƒç±»
        """
        trainer = self
        
        class TrainingCallback:
            """Coqui TTS è®­ç»ƒå›è°ƒ"""
            
            def on_train_step_end(self, trainer_obj, outputs: dict, step: int, epoch: int):
                """è®­ç»ƒæ­¥éª¤ç»“æŸæ—¶è°ƒç”¨"""
                if trainer._should_stop:
                    raise KeyboardInterrupt("ç”¨æˆ·è¯·æ±‚åœæ­¢è®­ç»ƒ")
                
                # æå–æŸå¤±å€¼
                loss = outputs.get("loss", 0.0)
                mel_loss = outputs.get("mel_loss", 0.0) or outputs.get("loss_mel", 0.0)
                duration_loss = outputs.get("duration_loss", 0.0) or outputs.get("loss_duration", 0.0)
                kl_loss = outputs.get("kl_loss", 0.0) or outputs.get("loss_kl", 0.0)
                
                trainer._update_progress(
                    current_step=step,
                    current_epoch=epoch,
                    loss=float(loss) if loss else 0.0,
                    mel_loss=float(mel_loss) if mel_loss else 0.0,
                    duration_loss=float(duration_loss) if duration_loss else 0.0,
                    kl_loss=float(kl_loss) if kl_loss else 0.0,
                    status=TrainingStatus.TRAINING,
                    message=f"è®­ç»ƒä¸­: Epoch {epoch}, Step {step}, Loss: {loss:.4f}"
                )
            
            def on_epoch_start(self, trainer_obj):
                """Epoch å¼€å§‹æ—¶è°ƒç”¨"""
                trainer._log(f"å¼€å§‹ Epoch {trainer._progress.current_epoch + 1}")
            
            def on_epoch_end(self, trainer_obj):
                """Epoch ç»“æŸæ—¶è°ƒç”¨"""
                trainer._log(f"Epoch {trainer._progress.current_epoch} å®Œæˆ, Loss: {trainer._progress.loss:.4f}")
            
            def on_train_start(self, trainer_obj):
                """è®­ç»ƒå¼€å§‹æ—¶è°ƒç”¨"""
                trainer._log("è®­ç»ƒå¼€å§‹")
                trainer._update_progress(
                    status=TrainingStatus.TRAINING,
                    message="è®­ç»ƒå¼€å§‹"
                )
            
            def on_train_end(self, trainer_obj):
                """è®­ç»ƒç»“æŸæ—¶è°ƒç”¨"""
                trainer._log("è®­ç»ƒç»“æŸ")
        
        return TrainingCallback()
    
    def _is_coqui_available(self) -> bool:
        """æ£€æŸ¥ Coqui TTS æ˜¯å¦å¯ç”¨"""
        try:
            import TTS
            from TTS.api import TTS as TTSApi
            return True
        except ImportError:
            return False
    
    def train(self, dataset_path: Path, resume_from: Optional[Path] = None) -> TrainingResult:
        """
        æ‰§è¡Œè®­ç»ƒ
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆLJSpeech æ ¼å¼ï¼‰
            resume_from: æ–­ç‚¹ç»­è®­çš„æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        result = TrainingResult()
        self._logs = []
        self._should_stop = False
        
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºå‡†å¤‡ä¸­
            self._update_progress(
                status=TrainingStatus.PREPARING,
                message="æ­£åœ¨å‡†å¤‡è®­ç»ƒç¯å¢ƒ..."
            )
            
            # å‡†å¤‡è®­ç»ƒç›®å½•
            work_dir = self._prepare_training_directory()
            
            # æ£€æŸ¥ Coqui TTS æ˜¯å¦å¯ç”¨
            if self._is_coqui_available():
                result = self._run_real_training(dataset_path, work_dir, resume_from)
            else:
                self._log("è­¦å‘Š: Coqui TTS æœªå®‰è£…ï¼Œæ‰§è¡Œæ¨¡æ‹Ÿè®­ç»ƒ")
                result = self._run_simulated_training(dataset_path, work_dir)
            
        except Exception as e:
            self._log(f"è®­ç»ƒè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            self._log(traceback.format_exc())
            self._update_progress(
                status=TrainingStatus.FAILED,
                message=f"è®­ç»ƒå¤±è´¥: {e}"
            )
            result.success = False
            result.error_message = str(e)
        
        result.logs = self._logs.copy()
        return result
    
    def _run_real_training(self, dataset_path: Path, work_dir: Path, 
                          resume_from: Optional[Path] = None) -> TrainingResult:
        """
        æ‰§è¡ŒçœŸå®çš„ Coqui TTS è®­ç»ƒ
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
            work_dir: å·¥ä½œç›®å½•
            resume_from: æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        result = TrainingResult()
        
        try:
            # é‡è¦ï¼šå¿…é¡»åœ¨å¯¼å…¥ Trainer ä¹‹å‰åº”ç”¨ä¿®å¤ï¼
            # å› ä¸º Trainer å¯¼å…¥æ—¶ä¼šåŠ è½½ trainer_utilsï¼Œæˆ‘ä»¬éœ€è¦åœ¨é‚£ä¹‹å‰ patch
            
            # ä¿®å¤ BFloat16 å…¼å®¹æ€§é—®é¢˜
            # åœ¨ Apple Silicon ä¸Šä½¿ç”¨æ··åˆç²¾åº¦æ—¶ï¼ŒPyTorch ä¼šä½¿ç”¨ BFloat16
            # ä½† numpy ä¸æ”¯æŒ BFloat16ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸º float32
            self._apply_bfloat16_fix()
            
            # ä¿®å¤ MPS è®¾å¤‡æ”¯æŒ
            # Trainer çš„ setup_torch_training_env å‡½æ•°ä¸æ”¯æŒ MPSï¼Œéœ€è¦ patch
            self._apply_mps_fix()
            
            # æ³¨æ„ï¼šä» Coqui TTS 0.22.0 å¼€å§‹ï¼ŒTrainer ç§»åˆ°äº†ç‹¬ç«‹çš„ trainer åŒ…ä¸­
            # å¿…é¡»åœ¨åº”ç”¨ MPS ä¿®å¤ä¹‹åå†å¯¼å…¥ï¼
            from trainer import Trainer, TrainerArgs
            
            # åˆ›å»ºé…ç½®
            config = self._create_coqui_config(dataset_path)
            
            # ä¿å­˜é…ç½®æ–‡ä»¶
            config_path = work_dir / "config.json"
            config.save_json(str(config_path))
            self._log(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_path}")
            
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            output_path = self.config.output_path / "model"
            output_path.mkdir(parents=True, exist_ok=True)
            
            # è·å–æœ‰æ•ˆè®¾å¤‡å¹¶è®¾ç½® GPU å‚æ•°
            device = self.config.get_effective_device()
            
            # è®¾ç½® GPU å‚æ•°
            # - å¦‚æœæ˜¯ CUDA æˆ– MPSï¼Œè®¾ç½® gpu=0ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ª GPUï¼‰
            # - å¦‚æœæ˜¯ CPUï¼Œè®¾ç½® gpu=Noneï¼ˆä¸ä½¿ç”¨ GPUï¼‰
            gpu_id = 0 if device in ["cuda", "mps"] else None
            
            # åˆ›å»ºè®­ç»ƒå‚æ•°
            trainer_args = TrainerArgs(
                best_path=str(output_path),
                restore_path=str(resume_from) if resume_from else "",
                gpu=gpu_id,  # è®¾ç½® GPU è®¾å¤‡
            )
            
            # è®°å½•å¼€å§‹æ—¶é—´
            self._start_time = time.time()
            
            # æ›´æ–°çŠ¶æ€
            self._update_progress(
                status=TrainingStatus.TRAINING,
                message="è®­ç»ƒè¿›è¡Œä¸­...",
                total_epochs=self.config.epochs
            )
            
            # åŠ è½½è®­ç»ƒæ•°æ®
            self._log("åŠ è½½è®­ç»ƒæ•°æ®é›†...")
            from TTS.tts.datasets import load_tts_samples
            from TTS.tts.models.vits import Vits
            
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆ’åˆ†éªŒè¯é›†
            if config.run_eval and config.eval_split_size > 0:
                train_samples, eval_samples = load_tts_samples(
                    config.datasets,
                    eval_split=True,
                    eval_split_max_size=config.eval_split_max_size,
                    eval_split_size=config.eval_split_size,
                )
            else:
                # ä¸åˆ’åˆ†éªŒè¯é›†ï¼Œæ‰€æœ‰æ ·æœ¬ç”¨äºè®­ç»ƒ
                train_samples, _ = load_tts_samples(
                    config.datasets,
                    eval_split=False,
                )
                eval_samples = []
                self._log("å·²ç¦ç”¨éªŒè¯é›†ï¼Œæ‰€æœ‰æ ·æœ¬ç”¨äºè®­ç»ƒ")
            
            self._log(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_samples)}, éªŒè¯æ ·æœ¬æ•°: {len(eval_samples)}")
            
            # åˆ›å»º VITS æ¨¡å‹
            self._log("åˆ›å»º VITS æ¨¡å‹...")
            model = Vits.init_from_config(config, samples=train_samples + eval_samples)
            
            # åˆ›å»º Trainer
            self._log("åˆ›å»º Coqui TTS Trainer...")
            trainer = Trainer(
                trainer_args,
                config,
                output_path=str(output_path),
                model=model,
                train_samples=train_samples,
                eval_samples=eval_samples,
                gpu=gpu_id,  # è®¾ç½® GPU è®¾å¤‡
            )
            
            self._trainer = trainer
            
            # å¼€å§‹è®­ç»ƒ
            self._log("å¼€å§‹è®­ç»ƒ...")
            trainer.fit()
            
            # è®­ç»ƒå®Œæˆ
            result.success = True
            result.training_time = time.time() - self._start_time
            result.total_epochs = self._progress.current_epoch
            result.final_loss = self._progress.loss
            
            # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹
            model_files = list(output_path.glob("best_model*.pth")) or list(output_path.glob("*.pth"))
            if model_files:
                result.model_path = model_files[0]
                result.model_size = result.model_path.stat().st_size
                self._log(f"æ¨¡å‹å·²ä¿å­˜: {result.model_path}")
            
            # ä¿å­˜é…ç½®
            result.config_path = config_path
            
            # æŸ¥æ‰¾æ£€æŸ¥ç‚¹
            checkpoint_files = sorted(output_path.glob("checkpoint_*.pth"))
            if checkpoint_files:
                result.checkpoint_path = checkpoint_files[-1]
            
            self._update_progress(
                status=TrainingStatus.COMPLETED,
                message="è®­ç»ƒå®Œæˆ"
            )
            
        except KeyboardInterrupt:
            self._log("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            self._update_progress(
                status=TrainingStatus.CANCELLED,
                message="è®­ç»ƒå·²å–æ¶ˆ"
            )
            result.success = False
            result.error_message = "è®­ç»ƒè¢«ç”¨æˆ·å–æ¶ˆ"
            
        except Exception as e:
            self._log(f"è®­ç»ƒå¤±è´¥: {e}")
            import traceback
            self._log(traceback.format_exc())
            result.success = False
            result.error_message = str(e)
            self._update_progress(
                status=TrainingStatus.FAILED,
                message=f"è®­ç»ƒå¤±è´¥: {e}"
            )
        
        finally:
            self._trainer = None
        
        return result
    
    def _run_simulated_training(self, dataset_path: Path, work_dir: Path) -> TrainingResult:
        """
        æ‰§è¡Œæ¨¡æ‹Ÿè®­ç»ƒï¼ˆç”¨äºæµ‹è¯•æˆ– Coqui TTS æœªå®‰è£…æ—¶ï¼‰
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
            work_dir: å·¥ä½œç›®å½•
            
        Returns:
            è®­ç»ƒç»“æœ
        """
        result = TrainingResult()
        
        self._log("=" * 60)
        self._log("âš ï¸ è­¦å‘Š: Coqui TTS æœªå®‰è£…ï¼")
        self._log("=" * 60)
        self._log("å°†ä½¿ç”¨ã€æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼ã€‘ï¼Œæ­¤æ¨¡å¼ä¸ä¼šç”Ÿæˆæœ‰æ•ˆçš„æ¨¡å‹ã€‚")
        self._log("æ¨¡æ‹Ÿè®­ç»ƒä»…ç”¨äºæµ‹è¯•è®­ç»ƒæµç¨‹ã€‚")
        self._log("")
        self._log("å¦‚éœ€è®­ç»ƒçœŸæ­£çš„ TTS æ¨¡å‹ï¼Œè¯·å…ˆå®‰è£… Coqui TTS:")
        self._log("  pip install TTS>=0.22.0")
        self._log("æˆ–ä½¿ç”¨:")
        self._log("  uv sync --extra training")
        self._log("=" * 60)
        
        self._log("å¼€å§‹æ¨¡æ‹Ÿè®­ç»ƒ...")
        self._start_time = time.time()
        
        total_epochs = min(self.config.epochs, 10)  # æ¨¡æ‹Ÿè®­ç»ƒæœ€å¤š10è½®
        steps_per_epoch = 100
        
        try:
            for epoch in range(1, total_epochs + 1):
                if self._should_stop:
                    self._update_progress(
                        status=TrainingStatus.CANCELLED,
                        message="è®­ç»ƒå·²å–æ¶ˆ"
                    )
                    result.error_message = "è®­ç»ƒè¢«ç”¨æˆ·å–æ¶ˆ"
                    return result
                
                for step in range(1, steps_per_epoch + 1):
                    if self._should_stop:
                        break
                    
                    # æ¨¡æ‹ŸæŸå¤±å€¼é€æ¸ä¸‹é™
                    progress = (epoch - 1) * steps_per_epoch + step
                    total_progress = total_epochs * steps_per_epoch
                    simulated_loss = 2.0 * (1 - progress / total_progress) + 0.1
                    
                    self._update_progress(
                        current_epoch=epoch,
                        total_epochs=total_epochs,
                        current_step=step,
                        total_steps=steps_per_epoch,
                        loss=simulated_loss,
                        mel_loss=simulated_loss * 0.6,
                        kl_loss=simulated_loss * 0.2,
                        learning_rate=self.config.learning_rate * (0.99 ** epoch),
                        status=TrainingStatus.TRAINING,
                        message=f"æ¨¡æ‹Ÿè®­ç»ƒ: Epoch {epoch}/{total_epochs}, Step {step}/{steps_per_epoch}"
                    )
                    
                    # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
                    time.sleep(0.02)
                
                self._log(f"Epoch {epoch}/{total_epochs} å®Œæˆ, Loss: {self._progress.loss:.4f}")
            
            # åˆ›å»ºæ¨¡æ‹Ÿçš„è®­ç»ƒä¿¡æ¯æ–‡ä»¶
            model_dir = self.config.output_path / "model"
            model_dir.mkdir(parents=True, exist_ok=True)
            
            info_path = model_dir / f"{self.config.speaker_name}_training_info.json"
            
            model_info = {
                "speaker_name": self.config.speaker_name,
                "model_type": self.config.model_type,
                "sample_rate": self.config.sample_rate,
                "epochs": total_epochs,
                "final_loss": self._progress.loss,
                "language": self.config.language,
                "warning": "âš ï¸ è¿™æ˜¯æ¨¡æ‹Ÿè®­ç»ƒç”Ÿæˆçš„ä¿¡æ¯æ–‡ä»¶ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ TTS æ¨¡å‹ï¼",
                "solution": "è¯·å®‰è£… Coqui TTS åé‡æ–°è®­ç»ƒ: pip install TTS>=0.22.0"
            }
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(model_info, f, indent=2, ensure_ascii=False)
            
            result.success = True
            result.model_path = info_path
            result.model_size = info_path.stat().st_size
            result.total_epochs = total_epochs
            result.final_loss = self._progress.loss
            result.training_time = time.time() - self._start_time
            
            self._update_progress(
                status=TrainingStatus.COMPLETED,
                message="æ¨¡æ‹Ÿè®­ç»ƒå®Œæˆï¼ˆæ³¨æ„ï¼šæœªç”Ÿæˆæœ‰æ•ˆçš„ TTS æ¨¡å‹ï¼‰"
            )
            
            self._log("âš ï¸ æ¨¡æ‹Ÿè®­ç»ƒå·²å®Œæˆï¼Œä½†ç”±äº Coqui TTS æœªå®‰è£…ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„æ¨¡å‹ï¼")
            self._log(f"è®­ç»ƒä¿¡æ¯å·²ä¿å­˜è‡³: {info_path}")
            
        except Exception as e:
            result.success = False
            result.error_message = str(e)
            self._update_progress(
                status=TrainingStatus.FAILED,
                message=f"æ¨¡æ‹Ÿè®­ç»ƒå¤±è´¥: {e}"
            )
        
        return result
    
    def stop(self) -> None:
        """åœæ­¢è®­ç»ƒ"""
        self._should_stop = True
        self._log("æ”¶åˆ°åœæ­¢è®­ç»ƒè¯·æ±‚...")
        
        if self._trainer:
            self._log("æ­£åœ¨åœæ­¢è®­ç»ƒ...")
    
    def pause(self) -> Optional[Path]:
        """
        æš‚åœè®­ç»ƒå¹¶ä¿å­˜æ£€æŸ¥ç‚¹
        
        Returns:
            æ£€æŸ¥ç‚¹è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        self._log("æš‚åœè®­ç»ƒ...")
        self._update_progress(
            status=TrainingStatus.PAUSED,
            message="è®­ç»ƒå·²æš‚åœ"
        )
        
        # ä¿å­˜å½“å‰çŠ¶æ€ä½œä¸ºæ£€æŸ¥ç‚¹
        checkpoint_dir = self.config.output_path / "training_workspace" / "checkpoints"
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint_path = checkpoint_dir / f"checkpoint_epoch_{self._progress.current_epoch}.json"
        
        checkpoint_data = {
            "epoch": self._progress.current_epoch,
            "step": self._progress.current_step,
            "loss": self._progress.loss,
            "learning_rate": self._progress.learning_rate,
            "elapsed_time": self._progress.elapsed_time,
            "config": self.config.to_dict()
        }
        
        with open(checkpoint_path, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
        
        self._log(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
        return checkpoint_path
    
    def get_progress(self) -> TrainingProgress:
        """
        è·å–å½“å‰è®­ç»ƒè¿›åº¦
        
        Returns:
            è®­ç»ƒè¿›åº¦å¯¹è±¡
        """
        return self._progress
    
    def get_logs(self) -> List[str]:
        """
        è·å–è®­ç»ƒæ—¥å¿—
        
        Returns:
            æ—¥å¿—åˆ—è¡¨
        """
        return self._logs.copy()


def create_trainer(config: TrainConfig, verbose: bool = False) -> CoquiTrainer:
    """
    åˆ›å»ºè®­ç»ƒå™¨å®ä¾‹çš„å·¥å‚å‡½æ•°
    
    Args:
        config: è®­ç»ƒé…ç½®
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        
    Returns:
        CoquiTrainer å®ä¾‹
    """
    return CoquiTrainer(config, verbose)
