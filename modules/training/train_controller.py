#!/usr/bin/env python3
"""
è®­ç»ƒæ¨¡å¼ä¸»æ§åˆ¶å™¨

æ•´åˆè®­ç»ƒæ•°æ®ç®¡ç†ã€éŸ³é¢‘å¯¹é½ã€Coqui TTS è®­ç»ƒç­‰æ¨¡å—ï¼Œ
å®ç°å®Œæ•´çš„è¯­éŸ³æ¨¡å‹è®­ç»ƒå·¥ä½œæµç¨‹ã€‚
"""

import logging
import time
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional, Callable, List, Dict, Any
from enum import Enum

from modules.training.train_config import TrainConfig
from modules.training.train_data_manager import (
    TrainDataManager,
    TrainDataPair,
    ScanResult,
    MediaFile,
)
from modules.audio_aligner import AudioAligner, AlignmentResult
from modules.training.coqui_trainer import (
    CoquiTrainer,
    TrainingProgress,
    TrainingResult,
    TrainingStatus,
)
from modules.training.coqui_checker import CoquiChecker, ensure_coqui_available
from modules.training.coqui_exporter import CoquiExporter, ExportResult
import re

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class TrainPhase(Enum):
    """è®­ç»ƒé˜¶æ®µæšä¸¾"""

    IDLE = "idle"  # ç©ºé—²
    CHECKING_DEPS = "checking_deps"  # æ£€æŸ¥ä¾èµ–
    SCANNING_DATA = "scanning_data"  # æ‰«ææ•°æ®
    MATCHING_FILES = "matching_files"  # åŒ¹é…æ–‡ä»¶
    GENERATING_SUBTITLES = "generating_subtitles"  # ç”Ÿæˆå­—å¹•
    ALIGNING_DATA = "aligning_data"  # å¯¹é½æ•°æ®
    PREPARING_DATASET = "preparing_dataset"  # å‡†å¤‡æ•°æ®é›†
    TRAINING = "training"  # è®­ç»ƒä¸­
    EXPORTING = "exporting"  # å¯¼å‡º ONNX
    COMPLETED = "completed"  # å®Œæˆ
    FAILED = "failed"  # å¤±è´¥


@dataclass
class TrainControllerProgress:
    """è®­ç»ƒæ§åˆ¶å™¨è¿›åº¦ä¿¡æ¯"""

    phase: TrainPhase = TrainPhase.IDLE
    phase_message: str = ""
    overall_progress: float = 0.0  # æ€»ä½“è¿›åº¦ (0-100)

    # å„é˜¶æ®µè¯¦æƒ…
    scan_result: Optional[ScanResult] = None
    matched_pairs: int = 0
    unmatched_files: int = 0
    alignment_progress: int = 0  # å·²å¯¹é½æ•°é‡
    alignment_total: int = 0  # æ€»æ•°é‡

    # è®­ç»ƒè¿›åº¦
    training_progress: Optional[TrainingProgress] = None

    # æ—¶é—´ç»Ÿè®¡
    start_time: float = 0
    elapsed_time: float = 0

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "phase": self.phase.value,
            "phase_message": self.phase_message,
            "overall_progress": self.overall_progress,
            "matched_pairs": self.matched_pairs,
            "unmatched_files": self.unmatched_files,
            "alignment_progress": self.alignment_progress,
            "alignment_total": self.alignment_total,
            "elapsed_time": self.elapsed_time,
            "training_progress": (
                self.training_progress.to_dict() if self.training_progress else None
            ),
        }


@dataclass
class TrainControllerResult:
    """è®­ç»ƒæ§åˆ¶å™¨ç»“æœ"""

    success: bool = False
    error_message: str = ""

    # æ•°æ®ç»Ÿè®¡
    total_audio_files: int = 0
    total_subtitle_files: int = 0
    matched_pairs: int = 0
    generated_subtitles: int = 0
    aligned_segments: int = 0
    total_audio_duration: float = 0.0  # æ€»éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

    # è®­ç»ƒç»“æœ
    training_result: Optional[TrainingResult] = None
    model_path: Optional[Path] = None

    # æ—¶é—´ç»Ÿè®¡
    total_time: float = 0.0

    # æ—¥å¿—
    logs: List[str] = field(default_factory=list)

    def get_summary(self) -> str:
        """è·å–ç»“æœæ‘˜è¦"""
        lines = [
            "=" * 60,
            "è®­ç»ƒç»“æœæ‘˜è¦",
            "=" * 60,
            f"çŠ¶æ€: {'æˆåŠŸ âœ…' if self.success else 'å¤±è´¥ âŒ'}",
        ]

        if self.error_message:
            lines.append(f"é”™è¯¯: {self.error_message}")

        lines.extend(
            [
                "",
                "æ•°æ®ç»Ÿè®¡:",
                f"  - éŸ³é¢‘æ–‡ä»¶: {self.total_audio_files}",
                f"  - å­—å¹•æ–‡ä»¶: {self.total_subtitle_files}",
                f"  - åŒ¹é…çš„æ•°æ®å¯¹: {self.matched_pairs}",
                f"  - è‡ªåŠ¨ç”Ÿæˆå­—å¹•: {self.generated_subtitles}",
                f"  - å¯¹é½çš„ç‰‡æ®µ: {self.aligned_segments}",
                f"  - æ€»éŸ³é¢‘æ—¶é•¿: {self._format_duration(self.total_audio_duration)}",
            ]
        )

        if self.training_result:
            lines.extend(
                [
                    "",
                    "è®­ç»ƒç»“æœ:",
                    f"  - è®­ç»ƒè½®æ•°: {self.training_result.total_epochs}",
                    f"  - æœ€ç»ˆæŸå¤±: {self.training_result.final_loss:.4f}",
                    f"  - è®­ç»ƒæ—¶é—´: {self._format_duration(self.training_result.training_time)}",
                ]
            )

            if self.model_path:
                lines.append(f"  - æ¨¡å‹è·¯å¾„: {self.model_path}")
                if self.training_result.model_size > 0:
                    size_mb = self.training_result.model_size / (1024 * 1024)
                    lines.append(f"  - æ¨¡å‹å¤§å°: {size_mb:.2f} MB")

        lines.extend(
            [
                "",
                f"æ€»è€—æ—¶: {self._format_duration(self.total_time)}",
                "=" * 60,
            ]
        )

        return "\n".join(lines)

    @staticmethod
    def _format_duration(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é•¿"""
        if seconds < 60:
            return f"{seconds:.1f} ç§’"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            secs = seconds % 60
            return f"{minutes} åˆ† {secs:.0f} ç§’"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            return f"{hours} å°æ—¶ {minutes} åˆ†"


# è¿›åº¦å›è°ƒç±»å‹
ControllerProgressCallback = Callable[[TrainControllerProgress], None]


class TrainController:
    """
    è®­ç»ƒæ¨¡å¼ä¸»æ§åˆ¶å™¨

    æ•´åˆå®Œæ•´çš„è®­ç»ƒå·¥ä½œæµï¼š
    1. æ£€æŸ¥ Coqui TTS ä¾èµ–
    2. æ‰«æå’ŒåŒ¹é…è®­ç»ƒæ•°æ®
    3. ä¸ºæ— å­—å¹•çš„åª’ä½“æ–‡ä»¶ç”Ÿæˆå­—å¹•ï¼ˆä½¿ç”¨ Whisperï¼‰
    4. å¯¹é½éŸ³é¢‘å’Œå­—å¹•
    5. å‡†å¤‡ LJSpeech æ ¼å¼æ•°æ®é›†
    6. æ‰§è¡Œ Coqui TTS è®­ç»ƒ
    7. å¯¼å‡º ONNX æ¨¡å‹
    8. è¾“å‡ºè®­ç»ƒç»“æœ
    """

    def __init__(self, config: TrainConfig, verbose: bool = False):
        """
        åˆå§‹åŒ–è®­ç»ƒæ§åˆ¶å™¨

        Args:
            config: è®­ç»ƒé…ç½®
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        """
        self.config = config
        self.verbose = verbose

        # åˆå§‹åŒ–å„æ¨¡å—
        self._data_manager = TrainDataManager(output_dir=config.output_path)
        self._aligner = AudioAligner(config)
        self._trainer = CoquiTrainer(config, verbose)
        self._checker = CoquiChecker()
        self._exporter = CoquiExporter(verbose)

        # è¿›åº¦è·Ÿè¸ª
        self._progress = TrainControllerProgress()
        self._callbacks: List[ControllerProgressCallback] = []
        self._logs: List[str] = []
        self._should_stop = False

        # Whisper ç”Ÿæˆå™¨ï¼ˆå»¶è¿Ÿå¯¼å…¥ï¼‰
        self._whisper_generator = None

    def add_progress_callback(self, callback: ControllerProgressCallback) -> None:
        """æ·»åŠ è¿›åº¦å›è°ƒ"""
        self._callbacks.append(callback)

    def remove_progress_callback(self, callback: ControllerProgressCallback) -> None:
        """ç§»é™¤è¿›åº¦å›è°ƒ"""
        if callback in self._callbacks:
            self._callbacks.remove(callback)

    def _notify_progress(self) -> None:
        """é€šçŸ¥è¿›åº¦æ›´æ–°"""
        for callback in self._callbacks:
            try:
                callback(self._progress)
            except Exception as e:
                self._log(f"è¿›åº¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")

    def _log(self, message: str, force_print: bool = False) -> None:
        """è®°å½•æ—¥å¿—

        Args:
            message: æ—¥å¿—æ¶ˆæ¯
            force_print: æ˜¯å¦å¼ºåˆ¶æ‰“å°åˆ°ç»ˆç«¯ï¼ˆä¸å— verbose è®¾ç½®å½±å“ï¼‰
        """
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self._logs.append(log_entry)
        logger.info(message)
        if self.verbose or force_print:
            print(log_entry)

    def _update_progress(
        self,
        phase: Optional[TrainPhase] = None,
        message: Optional[str] = None,
        overall: Optional[float] = None,
        **kwargs,
    ) -> None:
        """æ›´æ–°è¿›åº¦"""
        if phase is not None:
            self._progress.phase = phase
        if message is not None:
            self._progress.phase_message = message
        if overall is not None:
            self._progress.overall_progress = overall

        for key, value in kwargs.items():
            if hasattr(self._progress, key):
                setattr(self._progress, key, value)

        # æ›´æ–°å·²ç”¨æ—¶é—´
        if self._progress.start_time > 0:
            self._progress.elapsed_time = time.time() - self._progress.start_time

        self._notify_progress()

    def run(self, resume_from: Optional[Path] = None) -> TrainControllerResult:
        """
        æ‰§è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹

        Args:
            resume_from: æ–­ç‚¹ç»­è®­çš„æ£€æŸ¥ç‚¹è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            TrainControllerResult: è®­ç»ƒç»“æœ
        """
        result = TrainControllerResult()
        self._logs = []
        self._should_stop = False
        self._progress.start_time = time.time()

        try:
            # é˜¶æ®µ 1: æ£€æŸ¥ä¾èµ–
            self._log("=" * 60)
            self._log("å¼€å§‹è®­ç»ƒæµç¨‹")
            self._log("=" * 60)

            if not self._check_dependencies():
                result.error_message = "ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·ç¡®ä¿å·²å®‰è£… Coqui TTS"
                result.logs = self._logs.copy()
                return result

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 2: æ‰«æè®­ç»ƒæ•°æ®
            scan_result = self._scan_training_data()
            if scan_result.total_count == 0:
                result.error_message = "æœªæ‰¾åˆ°ä»»ä½•è®­ç»ƒæ•°æ®"
                result.logs = self._logs.copy()
                return result

            result.total_audio_files = len(scan_result.audio_files)
            result.total_subtitle_files = len(scan_result.subtitle_files)

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 3: åŒ¹é…æ–‡ä»¶
            matched_pairs, unmatched = self._match_files(scan_result)
            result.matched_pairs = len(matched_pairs)

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 4: ä¸ºæœªåŒ¹é…çš„åª’ä½“æ–‡ä»¶ç”Ÿæˆå­—å¹•
            if unmatched:
                new_pairs, generated_count = self._generate_missing_subtitles(unmatched)
                matched_pairs.extend(new_pairs)
                result.generated_subtitles = generated_count
                result.matched_pairs = len(matched_pairs)

            if not matched_pairs:
                result.error_message = "æ²¡æœ‰å¯ç”¨çš„è®­ç»ƒæ•°æ®å¯¹"
                result.logs = self._logs.copy()
                return result

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 5: å¯¹é½æ•°æ®
            alignment_results = self._align_data(matched_pairs)

            total_segments = 0
            total_duration = 0.0

            for align_result in alignment_results:
                if align_result.success:
                    total_segments += align_result.total_segments
                    total_duration += align_result.total_duration

            result.aligned_segments = total_segments
            result.total_audio_duration = total_duration

            # è¾“å‡ºå¯¹é½ç»Ÿè®¡ï¼ˆå¼ºåˆ¶æ‰“å°ï¼‰
            self._log(
                f"æ•°æ®å¯¹é½å®Œæˆ: {total_segments} ä¸ªç‰‡æ®µ, æ€»æ—¶é•¿ {total_duration:.1f} ç§’",
                force_print=True,
            )

            if total_segments == 0:
                result.error_message = "æ•°æ®å¯¹é½å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„è®­ç»ƒç‰‡æ®µ"
                result.logs = self._logs.copy()
                self._log(f"âŒ {result.error_message}", force_print=True)
                return result

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 6: å‡†å¤‡ LJSpeech æ ¼å¼æ•°æ®é›†
            dataset_path = self._prepare_ljspeech_dataset(alignment_results)

            if dataset_path is None:
                result.error_message = "æ•°æ®é›†å‡†å¤‡å¤±è´¥"
                result.logs = self._logs.copy()
                return result

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 7: æ‰§è¡Œè®­ç»ƒ
            training_result = self._run_training(dataset_path, resume_from)

            result.training_result = training_result
            result.model_path = training_result.model_path
            result.success = training_result.success

            if not training_result.success:
                result.error_message = training_result.error_message
                result.logs = self._logs.copy()
                return result

            if self._should_stop:
                return self._create_cancelled_result()

            # é˜¶æ®µ 8: å¯¼å‡º ONNX æ¨¡å‹
            if training_result.model_path:
                export_result = self._export_onnx_model(training_result)
                if export_result.success:
                    result.model_path = export_result.onnx_model_path

        except Exception as e:
            self._log(f"è®­ç»ƒè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            self._update_progress(phase=TrainPhase.FAILED, message=f"è®­ç»ƒå¤±è´¥: {e}")
            result.success = False
            result.error_message = str(e)

        # è®¡ç®—æ€»æ—¶é—´
        result.total_time = time.time() - self._progress.start_time
        result.logs = self._logs.copy()

        # è¾“å‡ºç»“æœæ‘˜è¦ï¼ˆå¼ºåˆ¶æ‰“å°ï¼Œå³ä½¿é verbose æ¨¡å¼ï¼‰
        self._log(result.get_summary(), force_print=True)

        return result

    def _check_dependencies(self) -> bool:
        """æ£€æŸ¥ä¾èµ–"""
        self._update_progress(
            phase=TrainPhase.CHECKING_DEPS,
            message="æ£€æŸ¥ Coqui TTS ä¾èµ–...",
            overall=5.0,
        )
        self._log("æ£€æŸ¥ Coqui TTS ä¾èµ–...")

        check_result = self._checker.check()

        if not check_result.is_installed:
            # Coqui TTS æœªå®‰è£…æ—¶ç»™å‡ºè­¦å‘Šï¼Œä½†ç»§ç»­æ‰§è¡Œï¼ˆå°†ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒï¼‰
            self._log(
                f"âš ï¸ Coqui TTS æœªå®‰è£…: {check_result.error_message}", force_print=True
            )
            self._log("âš ï¸ å°†ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒæ¨¡å¼ï¼ˆä¸ä¼šç”ŸæˆçœŸå®æ¨¡å‹ï¼‰", force_print=True)
            self._checker.print_install_guide()
            return True  # å…è®¸ç»§ç»­ï¼ŒCoquiTrainer ä¼šè‡ªåŠ¨ä½¿ç”¨æ¨¡æ‹Ÿè®­ç»ƒ

        if not check_result.is_compatible:
            self._log(f"âš ï¸ Coqui TTS ç‰ˆæœ¬ä¸å…¼å®¹: {check_result.error_message}")
            # ç‰ˆæœ¬ä¸å…¼å®¹æ—¶ç»™å‡ºè­¦å‘Šï¼Œä½†ç»§ç»­æ‰§è¡Œ

        self._log(f"âœ… Coqui TTS æ£€æŸ¥é€šè¿‡ (ç‰ˆæœ¬: {check_result.version})")

        # æ˜¾ç¤º GPU çŠ¶æ€
        if check_result.cuda_available:
            self._log(
                f"âœ… GPU å¯ç”¨: {check_result.gpu_name} ({check_result.gpu_memory}), CUDA {check_result.cuda_version}"
            )
        elif check_result.mps_available:
            # è·å– Apple Silicon ä¿¡æ¯
            mps_name, mps_memory = self._checker._get_mps_info()
            gpu_info = mps_name or "Apple Silicon GPU"
            if mps_memory:
                self._log(f"âœ… GPU å¯ç”¨: {gpu_info} ({mps_memory}), Metal (MPS)")
            else:
                self._log(f"âœ… GPU å¯ç”¨: {gpu_info}, Metal (MPS)")
            self._log("â„¹ï¸  æ³¨æ„: MPS åç«¯å¯¹éƒ¨åˆ†æ“ä½œæ”¯æŒæœ‰é™ï¼Œå¦‚é‡é—®é¢˜å¯å°è¯• CPU è®­ç»ƒ")
        else:
            self._log("âš ï¸ GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

        return True

    def _scan_training_data(self) -> ScanResult:
        """æ‰«æè®­ç»ƒæ•°æ®"""
        self._update_progress(
            phase=TrainPhase.SCANNING_DATA, message="æ‰«æè®­ç»ƒæ•°æ®...", overall=10.0
        )
        self._log("æ‰«æè®­ç»ƒæ•°æ®...")

        # æ ¹æ®é…ç½®å†³å®šæ‰«ææ–¹å¼
        if self.config.input_dir:
            self._log(f"æ‰«æç›®å½•: {self.config.input_dir}")
            scan_result = self._data_manager.scan_directory(self.config.input_dir)
        else:
            self._log("ä»é…ç½®çš„æ–‡ä»¶åˆ—è¡¨æ‰«æ...")
            scan_result = self._data_manager.scan_files(
                audio_files=self.config.audio_files,
                subtitle_files=self.config.subtitle_files,
            )

        self._progress.scan_result = scan_result
        self._log(scan_result.summary())

        return scan_result

    def _match_files(
        self, scan_result: ScanResult
    ) -> tuple[List[TrainDataPair], List[MediaFile]]:
        """åŒ¹é…éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶"""
        self._update_progress(
            phase=TrainPhase.MATCHING_FILES,
            message="åŒ¹é…éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶...",
            overall=20.0,
        )
        self._log("åŒ¹é…éŸ³é¢‘å’Œå­—å¹•æ–‡ä»¶...")

        matched_pairs, unmatched = self._data_manager.match_audio_subtitle(
            scan_result, extract_from_video=True
        )

        self._progress.matched_pairs = len(matched_pairs)
        self._progress.unmatched_files = len(unmatched)

        self._log(f"åŒ¹é…å®Œæˆ: {len(matched_pairs)} å¯¹æˆåŠŸ, {len(unmatched)} ä¸ªæœªåŒ¹é…")

        return matched_pairs, unmatched

    def _generate_missing_subtitles(
        self, unmatched: List[MediaFile]
    ) -> tuple[List[TrainDataPair], int]:
        """ä¸ºæœªåŒ¹é…çš„åª’ä½“æ–‡ä»¶ç”Ÿæˆå­—å¹•"""
        self._update_progress(
            phase=TrainPhase.GENERATING_SUBTITLES,
            message="ä½¿ç”¨ Whisper ç”Ÿæˆç¼ºå¤±çš„å­—å¹•...",
            overall=30.0,
        )

        # è·å–éœ€è¦ç”Ÿæˆå­—å¹•çš„åª’ä½“æ–‡ä»¶
        media_for_whisper = self._data_manager.get_unmatched_media_for_whisper(
            unmatched
        )

        if not media_for_whisper:
            self._log("æ²¡æœ‰éœ€è¦ç”Ÿæˆå­—å¹•çš„åª’ä½“æ–‡ä»¶")
            return [], 0

        self._log(f"éœ€è¦ä¸º {len(media_for_whisper)} ä¸ªåª’ä½“æ–‡ä»¶ç”Ÿæˆå­—å¹•...")

        new_pairs = []
        generated_count = 0

        # å»¶è¿Ÿå¯¼å…¥ Whisper ç”Ÿæˆå™¨
        try:
            from modules.whisper.whisper_subtitle_generator import (
                WhisperSubtitleGenerator,
            )

            if self._whisper_generator is None:
                self._whisper_generator = WhisperSubtitleGenerator()

            subtitle_output_dir = self.config.output_path / "generated_subtitles"
            subtitle_output_dir.mkdir(parents=True, exist_ok=True)

            for i, media in enumerate(media_for_whisper):
                if self._should_stop:
                    break

                self._log(
                    f"[{i+1}/{len(media_for_whisper)}] ä¸º {media.path.name} ç”Ÿæˆå­—å¹•..."
                )

                try:
                    # ä½¿ç”¨ Whisper ç”Ÿæˆå­—å¹•
                    subtitle_path = subtitle_output_dir / f"{media.stem}.srt"

                    gen_result = self._whisper_generator.generate_subtitle(
                        media_path=media.path, output_path=subtitle_path
                    )
                    success = gen_result.success

                    if success and subtitle_path.exists():
                        # ç¡®å®šéŸ³é¢‘è·¯å¾„
                        if media.media_type.value == "video":
                            # ä»è§†é¢‘æå–éŸ³é¢‘
                            audio_path = self._data_manager.extract_audio_from_video(
                                media.path, sample_rate=self.config.sample_rate
                            )
                        else:
                            audio_path = media.path

                        new_pairs.append(
                            TrainDataPair(
                                audio_path=audio_path,
                                subtitle_path=subtitle_path,
                                source_video=(
                                    media.path
                                    if media.media_type.value == "video"
                                    else None
                                ),
                            )
                        )
                        generated_count += 1
                        self._log(f"  âœ… å­—å¹•ç”ŸæˆæˆåŠŸ: {subtitle_path.name}")
                    else:
                        self._log(f"  âŒ å­—å¹•ç”Ÿæˆå¤±è´¥")

                except Exception as e:
                    self._log(f"  âŒ ç”Ÿæˆå­—å¹•æ—¶å‡ºé”™: {e}")

                # æ›´æ–°è¿›åº¦
                progress = 30.0 + (i + 1) / len(media_for_whisper) * 10.0
                self._update_progress(overall=progress)

        except ImportError:
            self._log("âš ï¸ Whisper å­—å¹•ç”Ÿæˆå™¨ä¸å¯ç”¨ï¼Œè·³è¿‡å­—å¹•ç”Ÿæˆ")
        except Exception as e:
            self._log(f"âš ï¸ å­—å¹•ç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")

        self._log(f"å­—å¹•ç”Ÿæˆå®Œæˆ: æˆåŠŸ {generated_count} ä¸ª")
        return new_pairs, generated_count

    def _align_data(self, pairs: List[TrainDataPair]) -> List[AlignmentResult]:
        """å¯¹é½éŸ³é¢‘å’Œå­—å¹•æ•°æ®"""
        self._update_progress(
            phase=TrainPhase.ALIGNING_DATA,
            message="å¯¹é½éŸ³é¢‘å’Œå­—å¹•æ•°æ®...",
            overall=45.0,
            alignment_total=len(pairs),
            alignment_progress=0,
        )
        self._log(f"å¼€å§‹å¯¹é½ {len(pairs)} å¯¹æ•°æ®...")

        results = []

        for i, pair in enumerate(pairs):
            if self._should_stop:
                break

            self._log(f"[{i+1}/{len(pairs)}] å¯¹é½: {pair.audio_path.name}")

            # ä¸ºæ¯å¯¹æ•°æ®åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
            pair_output_dir = self.config.output_path / "aligned" / f"pair_{i:04d}"

            result = self._aligner.align(
                audio_path=pair.audio_path,
                subtitle_path=pair.subtitle_path,
                output_dir=pair_output_dir,
            )

            results.append(result)

            if result.success:
                self._log(
                    f"  âœ… å¯¹é½æˆåŠŸ: {result.total_segments} ä¸ªç‰‡æ®µ, "
                    f"{result.total_duration:.1f} ç§’"
                )
            else:
                self._log(f"  âŒ å¯¹é½å¤±è´¥: {result.error_message}")

            # æ›´æ–°è¿›åº¦
            self._update_progress(
                alignment_progress=i + 1, overall=45.0 + (i + 1) / len(pairs) * 20.0
            )

        successful = sum(1 for r in results if r.success)
        self._log(f"æ•°æ®å¯¹é½å®Œæˆ: {successful}/{len(pairs)} æˆåŠŸ")

        return results

    def _detect_language_from_text(self, texts: List[str]) -> str:
        """ä»æ–‡æœ¬æ ·æœ¬ä¸­æ£€æµ‹è¯­è¨€
        
        Args:
            texts: æ–‡æœ¬æ ·æœ¬åˆ—è¡¨
            
        Returns:
            str: æ£€æµ‹åˆ°çš„è¯­è¨€ä»£ç  (en, zh-cn, ja, ko ç­‰)
        """
        if not texts:
            return "en"  # é»˜è®¤è‹±è¯­
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬è¿›è¡Œåˆ†æ
        sample_text = " ".join(texts[:100])  # å–å‰100ä¸ªæ ·æœ¬
        
        # ç»Ÿè®¡ä¸åŒå­—ç¬¦ç±»å‹çš„æ•°é‡
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', sample_text))
        japanese_chars = len(re.findall(r'[\u3040-\u309f\u30a0-\u30ff]', sample_text))
        korean_chars = len(re.findall(r'[\uac00-\ud7af]', sample_text))
        latin_chars = len(re.findall(r'[a-zA-Z]', sample_text))
        
        total_chars = len(sample_text.replace(" ", ""))
        
        if total_chars == 0:
            return "en"
        
        # è®¡ç®—å„è¯­è¨€å­—ç¬¦å æ¯”
        chinese_ratio = chinese_chars / total_chars
        japanese_ratio = japanese_chars / total_chars
        korean_ratio = korean_chars / total_chars
        latin_ratio = latin_chars / total_chars
        
        # æ ¹æ®å æ¯”åˆ¤æ–­è¯­è¨€
        if chinese_ratio > 0.3:
            return "zh-cn"
        elif japanese_ratio > 0.2:
            return "ja"
        elif korean_ratio > 0.2:
            return "ko"
        elif latin_ratio > 0.5:
            return "en"
        else:
            # é»˜è®¤è¿”å›è‹±è¯­
            return "en"
    
    def _prepare_ljspeech_dataset(
        self, alignment_results: List[AlignmentResult]
    ) -> Optional[Path]:
        """å‡†å¤‡ LJSpeech æ ¼å¼æ•°æ®é›†"""
        self._update_progress(
            phase=TrainPhase.PREPARING_DATASET,
            message="å‡†å¤‡ LJSpeech æ ¼å¼æ•°æ®é›†...",
            overall=65.0,
        )
        self._log("å‡†å¤‡ LJSpeech æ ¼å¼æ•°æ®é›†...")

        # æ”¶é›†æ‰€æœ‰å¯¹é½æ•°æ®
        aligned_data = []
        text_samples = []  # ç”¨äºè¯­è¨€æ£€æµ‹
        for result in alignment_results:
            if result.success and result.segments:
                for segment in result.segments:
                    # AlignedSegment æ˜¯ dataclassï¼Œä½¿ç”¨å±æ€§è®¿é—®è€Œéå­—å…¸ get()
                    text = segment.text if hasattr(segment, "text") else ""
                    aligned_data.append(
                        {
                            "audio_path": (
                                str(segment.audio_path)
                                if hasattr(segment, "audio_path")
                                else ""
                            ),
                            "text": text,
                            "start_time": (
                                segment.start_time
                                if hasattr(segment, "start_time")
                                else 0
                            ),
                            "end_time": (
                                segment.end_time if hasattr(segment, "end_time") else 0
                            ),
                        }
                    )
                    if text:
                        text_samples.append(text)

        if not aligned_data:
            self._log("âŒ æ²¡æœ‰å¯¹é½æ•°æ®å¯ç”¨äºè®­ç»ƒ")
            return None
        
        # è‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼ˆå¦‚æœé…ç½®ä¸­ä½¿ç”¨çš„æ˜¯ auto æˆ–é»˜è®¤çš„ zh-cnï¼‰
        if text_samples and (self.config.language == "auto" or self.config.language == "zh-cn"):
            detected_language = self._detect_language_from_text(text_samples)
            
            # å¦‚æœæ˜¯ auto æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æ£€æµ‹ç»“æœ
            if self.config.language == "auto":
                self._log(f"ğŸ” è‡ªåŠ¨æ£€æµ‹åˆ°è®­ç»ƒæ•°æ®è¯­è¨€: {detected_language}")
                self.config.language = detected_language
                if hasattr(self.config, 'phoneme_language'):
                    self.config.phoneme_language = detected_language
            # å¦‚æœæ˜¯ zh-cn ä½†æ£€æµ‹åˆ°å…¶ä»–è¯­è¨€ï¼Œç»™å‡ºè­¦å‘Šå¹¶è°ƒæ•´
            elif detected_language != "zh-cn":
                self._log(f"âš ï¸  æ£€æµ‹åˆ°è®­ç»ƒæ•°æ®è¯­è¨€ä¸º '{detected_language}'ï¼Œä½†é…ç½®ä¸­è®¾ç½®ä¸º 'zh-cn'")
                self._log(f"âœ… è‡ªåŠ¨è°ƒæ•´è¯­è¨€é…ç½®ä¸º: {detected_language}")
                self.config.language = detected_language
                if hasattr(self.config, 'phoneme_language'):
                    self.config.phoneme_language = detected_language

        # ç”Ÿæˆ LJSpeech æ•°æ®é›†
        dataset_output_dir = self.config.output_path / "ljspeech_dataset"

        try:
            dataset_path, stats = self._data_manager.generate_ljspeech_dataset(
                aligned_data,
                dataset_output_dir,
                sample_rate=self.config.sample_rate,
                max_duration=self.config.max_audio_length,
                min_duration=self.config.min_audio_length,
            )

            self._log(
                f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ: {stats.total_clips} ä¸ªç‰‡æ®µ, "
                f"æ€»æ—¶é•¿: {stats.total_duration:.1f} ç§’"
            )

            return dataset_path

        except Exception as e:
            self._log(f"âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥: {e}")
            return None

    def _run_training(
        self, dataset_path: Path, resume_from: Optional[Path] = None
    ) -> TrainingResult:
        """æ‰§è¡Œè®­ç»ƒ"""
        self._update_progress(
            phase=TrainPhase.TRAINING, message="å¼€å§‹ Coqui TTS è®­ç»ƒ...", overall=70.0
        )
        self._log("å¼€å§‹ Coqui TTS è®­ç»ƒ...")
        self._log(self.config.get_summary())

        # æ·»åŠ è®­ç»ƒè¿›åº¦å›è°ƒ
        def on_training_progress(progress: TrainingProgress):
            self._progress.training_progress = progress
            # è®­ç»ƒé˜¶æ®µå  70% - 100% çš„è¿›åº¦
            training_progress = progress.progress_percentage
            overall = 70.0 + training_progress * 0.3
            self._update_progress(
                overall=overall,
                message=f"è®­ç»ƒä¸­: Epoch {progress.current_epoch}/{progress.total_epochs}, "
                f"Loss: {progress.loss:.4f}",
            )

        self._trainer.add_progress_callback(on_training_progress)

        try:
            result = self._trainer.train(dataset_path, resume_from)

            if result.success:
                self._update_progress(
                    phase=TrainPhase.TRAINING,
                    message="è®­ç»ƒå®Œæˆï¼Œå‡†å¤‡å¯¼å‡ºæ¨¡å‹...",
                    overall=95.0,
                )
                self._log("âœ… è®­ç»ƒå®Œæˆ")
            else:
                self._update_progress(
                    phase=TrainPhase.FAILED, message=f"è®­ç»ƒå¤±è´¥: {result.error_message}"
                )
                self._log(f"âŒ è®­ç»ƒå¤±è´¥: {result.error_message}")

            return result

        finally:
            self._trainer.remove_progress_callback(on_training_progress)

    def _export_onnx_model(self, training_result: TrainingResult) -> ExportResult:
        """å¯¼å‡º ONNX æ¨¡å‹"""
        self._update_progress(
            phase=TrainPhase.EXPORTING, message="å¯¼å‡º ONNX æ¨¡å‹...", overall=97.0
        )
        self._log("å¯¼å‡º ONNX æ¨¡å‹...")

        try:
            onnx_output_dir = self.config.output_path / "onnx"

            result = self._exporter.export_to_onnx(
                model_path=training_result.model_path,
                output_dir=onnx_output_dir,
                config_path=training_result.config_path,
                model_name=self.config.speaker_name,
            )

            if result.success:
                self._log(f"âœ… ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸ: {result.onnx_model_path}")
                self._update_progress(
                    phase=TrainPhase.COMPLETED, message="è®­ç»ƒå’Œå¯¼å‡ºå®Œæˆ", overall=100.0
                )
            else:
                self._log(f"âš ï¸ ONNX å¯¼å‡ºå¤±è´¥: {result.error_message}")
                self._log("è®­ç»ƒæ¨¡å‹å·²ä¿å­˜ï¼Œä½† ONNX å¯¼å‡ºå¤±è´¥")
                # å³ä½¿å¯¼å‡ºå¤±è´¥ï¼Œè®­ç»ƒæœ¬èº«æ˜¯æˆåŠŸçš„
                self._update_progress(
                    phase=TrainPhase.COMPLETED,
                    message="è®­ç»ƒå®Œæˆï¼ˆONNX å¯¼å‡ºå¤±è´¥ï¼‰",
                    overall=100.0,
                )

            return result

        except Exception as e:
            self._log(f"âš ï¸ ONNX å¯¼å‡ºè¿‡ç¨‹å‡ºé”™: {e}")
            return ExportResult(success=False, error_message=str(e))

    def _create_cancelled_result(self) -> TrainControllerResult:
        """åˆ›å»ºå–æ¶ˆç»“æœ"""
        self._update_progress(phase=TrainPhase.FAILED, message="è®­ç»ƒå·²å–æ¶ˆ")
        result = TrainControllerResult()
        result.success = False
        result.error_message = "è®­ç»ƒè¢«ç”¨æˆ·å–æ¶ˆ"
        result.total_time = time.time() - self._progress.start_time
        result.logs = self._logs.copy()
        return result

    def stop(self) -> None:
        """åœæ­¢è®­ç»ƒ"""
        self._log("æ”¶åˆ°åœæ­¢è¯·æ±‚...")
        self._should_stop = True
        self._trainer.stop()

    def get_progress(self) -> TrainControllerProgress:
        """è·å–å½“å‰è¿›åº¦"""
        return self._progress

    def get_logs(self) -> List[str]:
        """è·å–æ—¥å¿—"""
        return self._logs.copy()


def create_train_controller(
    config: TrainConfig, verbose: bool = False
) -> TrainController:
    """
    åˆ›å»ºè®­ç»ƒæ§åˆ¶å™¨çš„å·¥å‚å‡½æ•°

    Args:
        config: è®­ç»ƒé…ç½®
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—

    Returns:
        TrainController å®ä¾‹
    """
    return TrainController(config, verbose)


def run_training(
    input_dir: Optional[Path] = None,
    output_path: Optional[Path] = None,
    speaker_name: str = "custom_speaker",
    epochs: int = 100,
    batch_size: int = 32,
    sample_rate: int = 22050,
    verbose: bool = False,
    **kwargs,
) -> TrainControllerResult:
    """
    ä¾¿æ·å‡½æ•°ï¼šæ‰§è¡Œè®­ç»ƒ

    Args:
        input_dir: è¾“å…¥æ•°æ®ç›®å½•
        output_path: è¾“å‡ºç›®å½•
        speaker_name: è¯´è¯äººåç§°
        epochs: è®­ç»ƒè½®æ•°
        batch_size: æ‰¹å¤„ç†å¤§å°
        sample_rate: é‡‡æ ·ç‡
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
        **kwargs: å…¶ä»–è®­ç»ƒé…ç½®å‚æ•°

    Returns:
        TrainControllerResult: è®­ç»ƒç»“æœ
    """
    config = TrainConfig(
        input_dir=input_dir,
        output_path=output_path or Path("./models/custom_voice"),
        speaker_name=speaker_name,
        epochs=epochs,
        batch_size=batch_size,
        sample_rate=sample_rate,
        verbose=verbose,
        **kwargs,
    )

    controller = TrainController(config, verbose)
    return controller.run()


if __name__ == "__main__":
    import sys

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.DEBUG,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )

    # ç®€å•çš„å‘½ä»¤è¡Œæµ‹è¯•
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python train_controller.py <è®­ç»ƒæ•°æ®ç›®å½•> [è¾“å‡ºç›®å½•] [è¯´è¯äººåç§°]")
        print("\nç¤ºä¾‹:")
        print("  python train_controller.py ./training_data")
        print(
            "  python train_controller.py ./training_data ./models/my_voice my_speaker"
        )
        sys.exit(1)

    input_dir = Path(sys.argv[1])
    output_path = (
        Path(sys.argv[2]) if len(sys.argv) > 2 else Path("./models/custom_voice")
    )
    speaker_name = sys.argv[3] if len(sys.argv) > 3 else "custom_speaker"

    print(f"\nå¼€å§‹è®­ç»ƒ:")
    print(f"  è¾“å…¥ç›®å½•: {input_dir}")
    print(f"  è¾“å‡ºç›®å½•: {output_path}")
    print(f"  è¯´è¯äºº: {speaker_name}")
    print()

    result = run_training(
        input_dir=input_dir,
        output_path=output_path,
        speaker_name=speaker_name,
        verbose=True,
    )

    print(result.get_summary())

    sys.exit(0 if result.success else 1)
