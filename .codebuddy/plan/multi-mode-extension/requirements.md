# 需求文档

## 引言

本需求文档描述了对现有命令行语音转文字工具的功能扩展计划。当前项目基于 OpenAI Whisper 实现音视频文件的语音识别和字幕生成功能。本次扩展将引入双模式架构，使项目能够根据用户传入的参数灵活切换以下两种功能：

1. **字幕提取模式（Whisper）**：保留现有功能，从视频/音频文件中提取字幕内容
2. **语音模型训练模式（Train）**：新增功能，利用 Mimic3 工具训练生成自定义语音模型

通过这种设计，项目将从单一的字幕提取工具扩展为一个多功能的语音处理平台。

## 需求

### 需求 1：命令行模式切换机制

**用户故事：** 作为一名开发者，我希望通过命令行参数选择不同的操作模式，以便能够灵活地使用字幕提取或语音模型训练功能。

#### 验收标准

1. WHEN 用户传入 `--whisper` 参数 THEN 系统 SHALL 进入字幕提取模式，执行现有的语音识别和字幕生成功能
2. WHEN 用户传入 `--train` 参数 THEN 系统 SHALL 进入语音模型训练模式，启动 Mimic3 训练流程
3. WHEN 用户同时传入 `--whisper` 和 `--train` 参数 THEN 系统 SHALL 显示互斥错误提示并退出
4. WHEN 用户未传入任何模式参数 THEN 系统 SHALL 显示帮助信息，提示用户选择操作模式
5. WHEN 用户传入 `--help` 参数 THEN 系统 SHALL 显示包含两种模式说明的完整帮助文档

### 需求 2：保留现有 Whisper 字幕提取功能

**用户故事：** 作为一名用户，我希望在传入 `--whisper` 参数时，项目能够保持当前的字幕提取功能不变，以便我可以继续从视频或音频文件中提取字幕。

#### 验收标准

1. WHEN 系统处于 `--whisper` 模式 AND 输入为视频文件 THEN 系统 SHALL 提取音频并执行语音识别生成字幕
2. WHEN 系统处于 `--whisper` 模式 AND 输入为音频文件 THEN 系统 SHALL 直接执行语音识别生成字幕
3. WHEN 系统处于 `--whisper` 模式 AND 输入为字幕文件 THEN 系统 SHALL 解析字幕文件并支持格式转换
4. WHEN 系统处于 `--whisper` 模式 THEN 系统 SHALL 支持现有的所有命令行参数（如 `--model`、`--language`、`--output` 等）
5. WHEN 系统处于 `--whisper` 模式 THEN 系统 SHALL 支持输出 SRT、VTT、TXT、JSON、CSV 等多种字幕格式

### 需求 3：新增 Mimic3 语音模型训练功能

**用户故事：** 作为一名开发者，我希望能够使用视频、音频和字幕文件作为训练数据，训练生成自定义的 Mimic3 语音模型，以便我可以创建特定说话人的语音合成模型。

#### 验收标准

1. WHEN 系统处于 `--train` 模式 AND 用户提供视频文件 THEN 系统 SHALL 提取音频用于训练数据
2. WHEN 系统处于 `--train` 模式 AND 用户提供音频文件 THEN 系统 SHALL 直接使用音频作为训练数据
3. WHEN 系统处于 `--train` 模式 AND 用户提供字幕文件 THEN 系统 SHALL 解析字幕作为训练文本标签
4. WHEN 系统处于 `--train` 模式 AND 音频与字幕文件匹配成功 THEN 系统 SHALL 自动对齐音频片段与文本标签
5. WHEN 训练数据准备完成 THEN 系统 SHALL 调用 Mimic3 训练接口开始模型训练
6. WHEN 训练完成 THEN 系统 SHALL 输出自定义语音模型文件到指定目录

### 需求 4：训练模式的数据输入管理

**用户故事：** 作为一名用户，我希望能够灵活地指定训练数据的输入方式，以便我可以使用不同来源的数据进行模型训练。

#### 验收标准

1. WHEN 用户传入 `--train-input` 参数指定目录 THEN 系统 SHALL 扫描目录下所有支持的媒体文件和字幕文件
2. WHEN 用户传入 `--train-audio` 参数 THEN 系统 SHALL 使用指定的音频文件作为训练音频
3. WHEN 用户传入 `--train-subtitle` 参数 THEN 系统 SHALL 使用指定的字幕文件作为训练文本
4. IF 用户仅提供视频文件而无对应字幕 THEN 系统 SHALL 先使用 Whisper 生成字幕再进行训练
5. WHEN 系统匹配音频与字幕时 THEN 系统 SHALL 基于文件名进行自动匹配
6. IF 音频与字幕无法自动匹配 THEN 系统 SHALL 提示用户手动指定对应关系

### 需求 5：训练模式的配置参数

**用户故事：** 作为一名开发者，我希望能够配置 Mimic3 训练的各项参数，以便我可以根据需要调整训练过程和输出结果。

#### 验收标准

1. WHEN 用户传入 `--train-output` 参数 THEN 系统 SHALL 将训练好的模型保存到指定目录
2. WHEN 用户传入 `--train-epochs` 参数 THEN 系统 SHALL 使用指定的训练轮数
3. WHEN 用户传入 `--train-batch-size` 参数 THEN 系统 SHALL 使用指定的批处理大小
4. WHEN 用户传入 `--train-sample-rate` 参数 THEN 系统 SHALL 使用指定的音频采样率
5. WHEN 用户传入 `--train-speaker-name` 参数 THEN 系统 SHALL 使用指定的说话人名称标识模型
6. IF 用户未指定训练参数 THEN 系统 SHALL 使用 Mimic3 的默认配置值

### 需求 6：训练进度与结果报告

**用户故事：** 作为一名用户，我希望能够了解训练进度和最终结果，以便我可以监控训练过程并评估模型质量。

#### 验收标准

1. WHEN 训练开始 THEN 系统 SHALL 显示训练数据统计信息（音频总时长、片段数量等）
2. WHEN 训练进行中 THEN 系统 SHALL 实时显示当前 epoch、损失值等进度信息
3. WHEN 训练完成 THEN 系统 SHALL 生成训练摘要报告（总耗时、最终损失值、模型大小等）
4. IF 训练过程中发生错误 THEN 系统 SHALL 记录错误信息并支持断点续训
5. WHEN 用户传入 `--verbose` 参数 THEN 系统 SHALL 输出详细的训练日志

### 需求 7：Mimic3 依赖管理

**用户故事：** 作为一名开发者，我希望系统能够自动管理 Mimic3 的依赖关系，以便我可以顺利完成环境配置和训练任务。

#### 验收标准

1. WHEN 用户首次使用 `--train` 模式 THEN 系统 SHALL 检查 Mimic3 是否已安装
2. IF Mimic3 未安装 THEN 系统 SHALL 提示安装命令并退出
3. WHEN Mimic3 已安装 THEN 系统 SHALL 验证版本兼容性
4. IF 版本不兼容 THEN 系统 SHALL 警告用户并建议升级或降级
5. WHEN 系统初始化训练模块 THEN 系统 SHALL 加载必要的 Mimic3 组件

## 技术约束

1. **Python 版本**：项目要求 Python >= 3.12
2. **Mimic3 集成**：需要集成 Mimic3 TTS 训练框架
3. **向后兼容**：`--whisper` 模式必须保持与现有功能完全兼容
4. **模块化设计**：新增的训练功能应作为独立模块实现，与现有代码解耦
5. **配置文件支持**：两种模式均应支持通过配置文件加载参数

## 成功标准

1. 使用 `--whisper` 模式时，所有现有功能正常运行，无回归问题
2. 使用 `--train` 模式时，能够成功完成语音模型训练并输出可用的模型文件
3. 命令行帮助信息清晰描述两种模式的使用方法和参数说明
4. 训练生成的模型可被 Mimic3 TTS 正确加载并合成语音
